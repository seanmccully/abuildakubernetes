#!/usr/bin/env bash
#
#MIT License
# ... (License text omitted for brevity) ...
#
# Doc:
#   Runs additional processes for building and configuring the cluster
#
declare -a pids;
pids_counter=0;
MESSAGE_HEADER="proc";

# Reliable script directory detection and sourcing common.sh
script_dir=$( cd -- "$( dirname -- "${BASH_SOURCE[0]}" )" &> /dev/null && pwd )
source "${script_dir}/common.sh";


function validate_certs() {
    info "started validate_certs";
    local cert_dir="${PKI_DIR}";

    # Find all .crt and .pub files in PKI_DIR (installed, decrypted certs)
    # Use mapfile/read to handle filenames safely
    while IFS= read -r _crt; do
        info "validate $_crt";
        local _key=""

        # Determine corresponding key file
        if [[ "$_crt" == *"/sa.pub" ]]; then
            _key="${_crt%/*}/sa.key"
        else
            # Replace .crt extension with .key
            _key="${_crt%.crt}.key"
        fi

        if [ ! -e "$_key" ]; then
            warning "validate_certs: key ${_key} does not exist for ${_crt}";
            continue
        fi

        certValidate "$_crt" "$_key";
        if [ $? -ne 0 ]; then
          # Treat validation failure as a critical error
          error_message "validate_certs - ${_crt} and ${_key} do not match or are invalid." 1
        fi
    done < <(find "$cert_dir" -type f \( -name "*.crt" -o -name "*.pub" \))
}

function generate_etcd_token() {
    info "started generate_etcd_token";
    # Generate only if it doesn't exist
    if [ ! -f "$ETCD_TOKEN_FILE" ]; then
      exec_c "openssl rand -hex -out ${ETCD_TOKEN_FILE} 32"
    fi

    if [ -f "$config_yaml" ]; then
        # Copy token to additional hosts
        # Use .[]? to handle empty list gracefully
        for host in $(yq_read ".hosts | .[]?" "$config_yaml"); do
            if [ -n "$host" ]; then
              exec_c "${SCP_COMMAND} ${ETCD_TOKEN_FILE} ${host}:${ETCD_TOKEN_FILE}"
            fi
        done
    fi
    info "finished generate_etcd_token";
}

# Updated function to use certs.yaml install_map for dynamic installation
function install_certs() {
    info "started install_certs";

    # Handle CA key decryption (CA keys are generated encrypted)
    local openssl_decrypt_key
    if [ -f "$PASS_FILE" ]; then
      # Define the command for decryption
      openssl_decrypt_key="openssl rsa -passin file:$PASS_FILE -in";
    else
      error_message "CA password file not found. Cannot decrypt CA keys." 1
      return 1
    fi

    # Setup system users
    info "install_certs setup systemd-sysusers";
    if [ -f "${CONF_DIR}/kubernetes-sysusers.conf" ] && [ -n "$SYSTEMD_SYSUSERS" ]; then
      exec_c "install -m 644 ${CONF_DIR}/kubernetes-sysusers.conf ${SYSUSERS_DIR}/kubernetes-sysusers.conf"
      exec_c "$SYSTEMD_SYSUSERS"

      if [ -f "$config_yaml" ]; then
          for host in $(yq_read ".hosts | .[]?" "$config_yaml"); do
              if [ -n "$host" ]; then
                exec_c "${SCP_COMMAND} ${CONF_DIR}/kubernetes-sysusers.conf ${host}:${SYSUSERS_DIR}/kubernetes-sysusers.conf"
                # Pass host argument correctly to exec_c
                exec_c "${SYSTEMD_SYSUSERS}" "$host"
              fi
          done
      fi
    fi

    # Define installation commands with appropriate permissions
    local inst_cert="install -o ${KUBE_USER} -g ${KUBE_GROUP} -m 644";
    local inst_key="install -o ${KUBE_USER} -g ${KUBE_GROUP} -m 600";
    local install_dir="install -d -o ${KUBE_USER} -g ${KUBE_GROUP} -m755";

    # Ensure base directories exist
    $install_dir "$PKI_DIR";
    # ETCD directory created here. Ownership is finalized in kube_configure.
    mkdir -p "$ETCD_PKI"

    # Check if CERTS_YAML exists
    if [ ! -f "$CERTS_YAML" ]; then
        error_message "Certs configuration file not found: ${CERTS_YAML}" 1
        return 1
    fi

    info "install_certs -- Installing Intermediate CAs"

    declare -A ca_dest_map=(
        ["kubernetes"]="ca"
        ["etcd"]="etcd/ca"
        ["kubernetes-front-proxy"]="front-proxy-ca"
    )

    # Iterate over the keys in the install_map to identify the CAs used.
    for intermediate in $(yq_read ".install_map | keys | .[]?" "$CERTS_YAML"); do
        if [ -n "$intermediate" ]; then
            # Source paths for the Intermediate CA files (generated by create_intermediate_ca)
            local src_cert="${CERT_DIR}/${intermediate}/certs/${intermediate}.cert.pem"
            local src_key="${CERT_DIR}/${intermediate}/private/${intermediate}.key.pem"

            # Determine destination based on standard map
            local dest_prefix="${ca_dest_map[$intermediate]}"

            if [ -z "$dest_prefix" ]; then
                # If a CA is listed in install_map but not in our standard destinations, warn and skip.
                warning "No standard destination found for CA: ${intermediate}. Skipping CA installation."
                continue
            fi

            local dest_cert="${PKI_DIR}/${dest_prefix}.crt"
            local dest_key="${PKI_DIR}/${dest_prefix}.key"

            if [ -f "$src_cert" ] && [ -f "$src_key" ]; then
                info "Installing CA: ${intermediate} to ${dest_prefix}.crt/key"
                # Install Cert
                exec_c "$inst_cert $src_cert $dest_cert"
                # Decrypt and Install Key (CA keys are encrypted)
                # We use standard bash execution due to redirection complexity with exec_c.
                if ! $openssl_decrypt_key "${src_key}" > "${dest_key}"; then
                    error_message "Failed to decrypt CA key: ${src_key}" 1
                fi
                chmod 0600 "${dest_key}"
                # Ownership is finalized at the end of the function.
            else
                error_message "Source files not found for Intermediate CA: ${intermediate}" 1
            fi
        fi
    done

    # --- Install Component Certificates (Iterating through install_map) ---
    info "install_certs -- Installing Component Certificates"

    for intermediate in $(yq_read ".install_map | keys | .[]?" "$CERTS_YAML"); do
        if [ -n "$intermediate" ]; then
            # Iterate through components and their destination prefixes
            for component in $(yq_read ".install_map.\"${intermediate}\" | keys | .[]?" "$CERTS_YAML"); do
                if [ -n "$component" ]; then
                    # Get the destination prefix defined in the YAML
                    local dest_prefix=$(yq_read ".install_map.\"${intermediate}\".\"${component}\"" "$CERTS_YAML")
                    local src_base="${CERT_DIR}/${intermediate}"
                    # Destination path is relative to PKI_DIR
                    local dest_base="${PKI_DIR}/${dest_prefix}"

                    info "Installing Component: ${intermediate}/${component} to ${dest_base}"

                    # Handle Service Account special case (pub/key instead of crt/key)
                    if [ "$component" == "service-accounts" ]; then
                        local src_key="${src_base}/private/${component}.key.pem"
                        local dest_key="${dest_base}.key"
                        local dest_pub="${dest_base}.pub"

                        if [ -f "$src_key" ]; then
                            # Install private key
                            exec_c "$inst_key $src_key $dest_key"
                            # Generate public key from private key (Standard practice for SA keys)
                            exec_c "openssl rsa -in $dest_key -pubout -out $dest_pub"
                            # Set permissions for the public key
                            exec_c "chmod 644 ${dest_pub}"
                            # Ownership finalized later
                        else
                             error_message "Source key not found for ${intermediate}/${component}" 1
                        fi
                    else
                        # Standard component installation (crt/key)
                        local src_cert="${src_base}/certs/${component}.cert.pem"
                        local src_key="${src_base}/private/${component}.key.pem"
                        local dest_cert="${dest_base}.crt"
                        local dest_key="${dest_base}.key"

                         if [ -f "$src_cert" ] && [ -f "$src_key" ]; then
                            # Ensure destination directory exists (e.g., for etcd/server.crt)
                            mkdir -p "$(dirname "$dest_cert")"
                            exec_c "$inst_cert $src_cert $dest_cert"
                            # Component keys are generated unencrypted by mkCert
                            exec_c "$inst_key $src_key $dest_key"
                        else
                             error_message "Source files not found for ${intermediate}/${component}" 1
                        fi
                    fi
                fi
            done
        fi
    done


    # Set final ownership (ETCD ownership is specifically set in kube_configure)
    # We set the base ownership here, kube_configure will override ETCD_PKI if necessary.
    exec_c "chown -R ${KUBE_USER}:${KUBE_GROUP} ${KUBE_PKI}"

    #validate_certs;
    info "finished install_certs";
}

function provision_calico() {
    info "started provision_calico";
    # CLUSTER_CIDR is used in calico_etcd_manifests
}


function calico_etcd_manifests() {
    info "started calico_manifests";

    local chart_values="${CALICO_SRC}/charts/calico/values.yaml";
    local calico_manifests="${CALICO_SRC}/manifests";
    local pool_yaml="/tmp/ippool.yaml"

    local calicoctl
    calicoctl=$(command -v calicoctl);
    local kubectl
    kubectl=$(command -v kubectl);

    if [ -z "$calicoctl" ] || [ -z "$kubectl" ]; then
      error_message "calicoctl or kubectl not found." 1
      return 1
    fi

    export GOROOT="${GOROOT}";
    export PATH="${GOROOT}/bin:${PATH}";

    # Install goimports if go is available
    if command -v go >/dev/null 2>&1; then
      go install golang.org/x/tools/cmd/goimports@latest || warning "Failed to install goimports"
    fi

    if [ ${#peer_ips[@]} -eq 0 ]; then
        set_peer_ips;
    fi
    local hostname
    hostname=$(hostname)
    local host_ip="${peer_ips[$hostname]}"

    local intf
    intf=$(ip -br -4 a sh | grep "${host_ip}" | awk '{print $1}');
    intf="${intf%%@*}"; # Remove potential trailing characters

    if [ -z "$intf" ]; then
      error_message "Could not determine network interface for IP ${host_ip}" 1
      return 1
    fi

    local mtu
    mtu=$(cat "/sys/class/net/${intf}/mtu");

    local cluster
    cluster=$(etcd_cluster_ips);

    # Read certificate contents and export as environment variables

    local etcd_cert=$(cat "${ETCD_PKI}/peer.crt")
    local etcd_key=$(cat "${ETCD_PKI}/peer.key")
    local etcd_ca=$(cat "${ETCD_PKI}/ca.crt")

    if [ ! -f "$chart_values" ]; then
      warning "Calico chart values file not found: ${chart_values}"
      return 1
    fi

	yq_write ".mtu=\"${mtu}\"" "$chart_values";
	yq_write ".etcd.endpoints=\"${cluster}\"" "$chart_values";
    yq_write '.etcd.tls.crt = $val' "$chart_values" "$etcd_cert"
    yq_write '.etcd.tls.key = $val' "$chart_values" "$etcd_key"
    yq_write '.etcd.tls.ca = $val' "$chart_values" "$etcd_ca"


    # Generate manifests (if go and necessary tools are available)
    if command -v go >/dev/null 2>&1; then
      pushd "${CALICO_SRC}/calicoctl/calicoctl/commands/crds" >/dev/null && go generate && popd >/dev/null
      if command -v goimports >/dev/null 2>&1; then
        pushd "${CALICO_SRC}" >/dev/null && find . -iname "*.go" ! -wholename "./vendor/*" | xargs goimports -w -local github.com/projectcalico/calico/ && popd >/dev/null
      fi
      pushd "${CALICO_SRC}" >/dev/null && make gen-manifests && popd >/dev/null
    fi

    # Apply manifests
    export KUBECONFIG=${KUBECONFIG:-"/root/.kube/config"};

    if [ ! -f "$KUBECONFIG" ]; then
      warning "Kubeconfig file not found: ${KUBECONFIG}, skipping Calico deployment."
      return 1
    fi

    if [ -f "${calico_manifests}/crds.yaml" ]; then
      exec_c "${kubectl} apply -f ${calico_manifests}/crds.yaml"
    fi

    # Create IP Pool
    cat > "$pool_yaml" <<EOF
apiVersion: projectcalico.org/v3
kind: IPPool
metadata:
  name: pool1
spec:
  cidr: ${CLUSTER_CIDR}
  ipipMode: Never
  natOutgoing: true
  disabled: false
  nodeSelector: all()
EOF

   exec_c "${calicoctl} create -f ${pool_yaml}"

   if [ -f "${calico_manifests}/calico-etcd.yaml" ]; then
    exec_c "${kubectl} apply -f ${calico_manifests}/calico-etcd.yaml"
   fi
}

function kubeconfig() {
    local kubectl
    kubectl=$(command -v kubectl);
    local kube_config=$1;
    local kube_user=$2;
    local ca_pem=$3;
    local kube_cert=$4;
    local kube_key=$5;

    info "started kubeconfig ${kube_config} ${kube_user} ${kube_cert}";

    if [ -z "$kubectl" ]; then
      error_message "kubectl not found." 1; return 1;
    fi

    if [ ! -f "$ca_pem" ]; then
      error_message "CA Certificate ${kube_user} files not found for ${ca_pem}." 1; return 1;
    fi
    if [ ! -f "$kube_cert" ]; then
      error_message "CA Certificate ${kube_user} files not found for ${kube_cert}." 1; return 1;
    fi
    if [ ! -f "$kube_key" ]; then
      error_message "CA Certificate ${kube_user} files not found for ${kube_key}." 1; return 1;
    fi

    exec_c "${kubectl} config set-cluster ${CLUSTER_NAME} \
	--certificate-authority=${ca_pem} --embed-certs=true \
	--server=${CLUSTER_ADDRESS} --kubeconfig=${kube_config}"

    exec_c "${kubectl} config set-credentials ${kube_user} \
	--client-certificate=${kube_cert} --client-key=${kube_key} \
	--embed-certs=true --kubeconfig=${kube_config}"

    exec_c "${kubectl} config set-context default --cluster=${CLUSTER_NAME} \
	--user=${kube_user} --kubeconfig=${kube_config}"

    exec_c "${kubectl} config use-context default --kubeconfig=${kube_config}"
    info "finished kubeconfig";
}

# Helper function to fetch component cert paths from CERT_DIR
function get_component_certs() {
    local component=$1
    local intermediate=$2
    local cert_var_name=$3
    local key_var_name=$4

    local cert_path="${CERT_DIR}/${intermediate}/certs/${component}.cert.pem"
    local key_path="${CERT_DIR}/${intermediate}/private/${component}.key.pem"

    if [ ! -f "$cert_path" ] || [ ! -f "$key_path" ]; then
        error_message "Component certificates not found for ${component} under ${intermediate} CA." 1
        return 1
    fi

    # Use declare -g to set the variable in the global scope (needed for calling function)
    declare -g "$cert_var_name"="$cert_path"
    declare -g "$key_var_name"="$key_path"
}


function create_kubeconfigs() {
    info "started create_kubeconfigs";

    local ca_cert="${PKI_DIR}/ca.crt"
    # Variables to hold paths returned by get_component_certs
    local component_crt=""
    local component_key=""

    mkdir -p "$KUBE_DIR"

    # Kube Controller Manager
    local component="kube-controller-manager";
    local intermediate="kubernetes";
    local component_config="${KUBE_DIR}/${component}.kubeconfig";
    local component_crt="${CERT_DIR}/${intermediate}/certs/system:${component}.cert.pem"
    local component_key="${CERT_DIR}/${intermediate}/private/system:${component}.key.pem"

    kubeconfig "$component_config" "$component" "$ca_cert" "$component_crt" "$component_key"
    exec_c "chmod 0400 $component_config"

    # Kube Scheduler
    #get_component_certs "kube-scheduler" "kubernetes" component_crt component_key
    component="kube-scheduler";
    component_config="${KUBE_DIR}/${component}.kubeconfig";
    component_crt="${CERT_DIR}/${intermediate}/certs/system:${component}.cert.pem"
    component_key="${CERT_DIR}/${intermediate}/private/system:${component}.key.pem"

    kubeconfig "$component_config" "$component" "$ca_cert" "$component_crt" "$component_key"
    exec_c "chmod 0400 $component_config"

    # Super Admin
    #get_component_certs "kubernetes-super-admin" "kubernetes" component_crt component_key
    #local super_admin_config="${KUBE_DIR}/super-admin.kubeconfig";

    component="kubernetes-super-admin";
    component_config="${KUBE_DIR}/${component}.kubeconfig";
    component_crt="${CERT_DIR}/${intermediate}/certs/${component}.cert.pem"
    component_key="${CERT_DIR}/${intermediate}/private/${component}.key.pem"

    kubeconfig "$component_config" "${component}" "$ca_cert" "$component_crt" "$component_key"
    exec_c "chmod 0400 $component_config"

    # Admin (for local usage)
    #get_component_certs "admin" "kubernetes" component_crt component_key
    mkdir -p /root/.kube
    local admin_config="/root/.kube/config";
    kubeconfig "$admin_config" "admin" "$ca_cert" "$component_crt" "$component_key"

    # Calico CNI
    #get_component_certs "calico-cni" "kubernetes" component_crt component_key
    component="calico-cni"
    local cni_config="${CNI_CONF_DIR}/calico-kubeconfig";
    component_crt="${CERT_DIR}/${intermediate}/certs/${component}.cert.pem"
    component_key="${CERT_DIR}/${intermediate}/private/${component}.key.pem"
    mkdir -p "$CNI_CONF_DIR"
    kubeconfig "$cni_config" "$component" "$ca_cert" "$component_crt" "$component_key"
    exec_c "chmod 600 ${cni_config}"

    # Kube Proxy
    local kube_proxy_dir
    kube_proxy_dir=$(yq_read '.kubeProxyDir' "$config_yaml");
    mkdir -p "$kube_proxy_dir"
    #get_component_certs "kube-proxy" "kubernetes" component_crt component_key
    component="kube-proxy"
    component_crt="${CERT_DIR}/${intermediate}/certs/${component}.cert.pem"
    component_key="${CERT_DIR}/${intermediate}/private/${component}.key.pem"
    kube_proxy_config="${kube_proxy_dir}/kubeconfig";
    # Kube-proxy authenticates as system:kube-proxy
    kubeconfig "$kube_proxy_config" "system:kube-proxy" "$ca_cert" "$component_crt" "$component_key"

    # Distribute necessary configs to remote hosts
    if [ -f "$config_yaml" ]; then
      for host in $(yq_read ".hosts | .[]?" "$config_yaml"); do
          if [ -n "$host" ]; then
            exec_c "mkdir -p ${kube_proxy_dir}" "$host"
            exec_c "$SCP_COMMAND $kube_proxy_config $host:${kube_proxy_config}"
            exec_c "mkdir -p ${CNI_CONF_DIR}" "$host"
            exec_c "$SCP_COMMAND $cni_config $host:${cni_config}"
          fi
      done
    fi
    info "finished create_kubeconfigs";
}

# Removed the redundant/conflicting kube_proxy function.

function create_kubelet_kubeconfig() {
    info "started create_kubelet_kubeconfig";
    local kubelet_dir
    kubelet_dir=$(yq_read '.kubeletDir' "$config_yaml");
    local ca_cert="${PKI_DIR}/ca.crt"
    mkdir -p "$kubelet_dir"

    # Local host
    local local_hostname
    local_hostname=$(hostname);
    local kubelet_crt_src="${CERT_DIR}/kubernetes/certs/${local_hostname}.cert.pem";
    local kubelet_key_src="${CERT_DIR}/kubernetes/private/${local_hostname}.key.pem";
    local kubelet_config="${kubelet_dir}/kubeconfig";

    if [ -f "$kubelet_crt_src" ] && [ -f "$kubelet_key_src" ]; then
        # Install certs locally (required by Kubelet configuration)
        exec_c "cp ${kubelet_crt_src} ${kubelet_dir}/kubelet.crt"
        exec_c "cp ${kubelet_key_src} ${kubelet_dir}/kubelet.key"
        # Kubelet authenticates as system:node:<hostname>
        kubeconfig "$kubelet_config" "system:node:${local_hostname}" "$ca_cert" "$kubelet_crt_src" "$kubelet_key_src"
    else
        warning "Kubelet certificates not found for local host ${local_hostname}."
    fi

    # Remote hosts
    if [ -f "$config_yaml" ]; then
        for host in $(yq_read ". | keys | .[]?" "$hosts_yaml"); do

            if [ -n "$host" ] && [ "$local_hostname" != "$host" ]; then
                kubelet_crt_src="$CERT_DIR/kubernetes/certs/$host.cert.pem";
                kubelet_key_src="$CERT_DIR/kubernetes/private/$host.key.pem";
                local kubelet_config_tmp="/tmp/kubelet-config-$host";

                if [ -f "$kubelet_crt_src" ] && [ -f "$kubelet_key_src" ]; then
                    kubeconfig "$kubelet_config_tmp" "system:node:${host}" "$ca_cert" "$kubelet_crt_src" "$kubelet_key_src"
                    exec_c "mkdir -p ${kubelet_dir}" "$host"
                    # Copy config and certs remotely
                    exec_c "${SCP_COMMAND} ${kubelet_config_tmp} ${host}:${kubelet_dir}/kubeconfig"
                    exec_c "${SCP_COMMAND} ${kubelet_crt_src} ${host}:${kubelet_dir}/kubelet.crt"
                    exec_c "${SCP_COMMAND} ${kubelet_key_src} ${host}:${kubelet_dir}/kubelet.key"
                    rm "${kubelet_config_tmp}";
                else
                    warning "Kubelet certificates not found for remote host ${host}."
                fi
            fi
        done
    fi
    info "finished create_kubelet_kubeconfig";
}

function kube_service_install() {
    info "started kube_service_install";

    local kubelet_dir
    kubelet_dir=$(yq_read '.kubeletDir' "$config_yaml");
    local kubelet_config="${kubelet_dir}/kubelet-config.yaml";
    local kube_proxy_dir
    kube_proxy_dir=$(yq_read '.kubeProxyDir' "$config_yaml");
    local kube_proxy_config="${kube_proxy_dir}/kube-proxy-config.yaml";

    if [ ! -d "$SERVICE_DIR" ] || [ ! -d "$CONF_DIR" ]; then
      error_message "Service or Config directory not found." 1; return 1;
    fi

    mkdir -p "$KUBE_DIR" "$kubelet_dir" "$kube_proxy_dir" /etc/sysctl.d/

    # Install files locally
    exec_c "install -m 644 ${SERVICE_DIR}/*.env ${KUBE_DIR}/"
    exec_c "install -m 644 ${SERVICE_DIR}/*.service ${SYSTEMD_SERVICE_PATH}"

    # Install configuration templates locally
    [ -f "${CONF_DIR}/50-sysctl.conf" ] && exec_c "install -m 644 ${CONF_DIR}/50-sysctl.conf /etc/sysctl.d/50-sysctl.conf"
    [ -f "${CONF_DIR}/kube-proxy-config.yaml" ] && exec_c "install -D -m 644 ${CONF_DIR}/kube-proxy-config.yaml ${kube_proxy_config}"
    [ -f "${CONF_DIR}/kubelet-config.yaml" ] && exec_c "install -D -m 644 ${CONF_DIR}/kubelet-config.yaml ${kubelet_config}"
    [ -f "${CONF_DIR}/kube-scheduler.yaml" ] && exec_c "install -D -m 644 ${CONF_DIR}/kube-scheduler.yaml ${KUBE_DIR}/kube-scheduler.yaml"

    # Load modules (use || true to ignore errors if already loaded or unavailable)
    exec_c "modprobe tcp_bbr || true"
    exec_c "depmod -a"
    exec_c "modprobe sch_cake || true"
    exec_c "depmod -a"

    # Set ownership
    exec_c "chown -R ${KUBE_USER}:${KUBE_GROUP} ${KUBE_DIR} ${kube_proxy_dir} ${kubelet_dir}"

    # Reload sysctl
    local sysctl
    sysctl=$(command -v sysctl);
    [ -n "$sysctl" ] && exec_c "${sysctl} --system > /dev/null"

    # Install on remote hosts
    if [ -f "$config_yaml" ]; then
      for host in $(yq_read ".hosts | .[]?" "$config_yaml"); do
          if [ -n "$host" ]; then
            info "Installing kubernetes service files on $host"
            
            # Create directories
            exec_c "mkdir -p $KUBE_DIR $kubelet_dir $kube_proxy_dir /etc/sysctl.d/" "$host"
            
            # Copy service files
            exec_c "$SCP_COMMAND $SERVICE_DIR/*.env $host:${KUBE_DIR}/"
            exec_c "$SCP_COMMAND $SERVICE_DIR/*.service $host:$SYSTEMD_SERVICE_PATH/"

            # Copy configuration files - THIS WAS MISSING kube-scheduler.yaml!
            [ -f "${CONF_DIR}/kube-proxy-config.yaml" ] && exec_c "$SCP_COMMAND $CONF_DIR/kube-proxy-config.yaml $host:$kube_proxy_config"
            [ -f "${CONF_DIR}/kubelet-config.yaml" ] && exec_c "$SCP_COMMAND $CONF_DIR/kubelet-config.yaml $host:$kubelet_config"
            [ -f "${CONF_DIR}/kube-scheduler.yaml" ] && exec_c "$SCP_COMMAND $CONF_DIR/kube-scheduler.yaml $host:$KUBE_DIR/kube-scheduler.yaml"
            [ -f "${CONF_DIR}/50-sysctl.conf" ] && exec_c "$SCP_COMMAND $CONF_DIR/50-sysctl.conf $host:/etc/sysctl.d/"

            # Load kernel modules
            exec_c "modprobe tcp_bbr || true && depmod -a" "$host"
            exec_c "modprobe sch_cake || true && depmod -a" "$host"

            # Apply sysctl settings
            [ -n "$sysctl" ] && exec_c "${sysctl} --system > /dev/null" "$host"

            # Set ownership
            exec_c "chown -R ${KUBE_USER}:${KUBE_GROUP} ${KUBE_DIR} ${kube_proxy_dir} ${kubelet_dir}" "$host"
          fi
      done
    fi
    info "finished kube_service_install";
}

# Alternative fix: Update setup_kube_scheduler to be more robust
function setup_kube_scheduler() {
    info "starting setup_kube_scheduler"
    local ks_env="${KUBE_DIR}/kube-scheduler.env";
    local ks_conf="${KUBE_DIR}/kube-scheduler.kubeconfig";
    local ks_yaml="${KUBE_DIR}/kube-scheduler.yaml";

    # Check if env file exists
    if [ ! -f "$ks_env" ]; then
      warning "kube-scheduler.env not found at ${ks_env}."
      return
    fi

    # Check if yaml template exists, if not create a basic one
    if [ ! -f "$ks_yaml" ]; then
      warning "kube-scheduler.yaml not found at ${ks_yaml}, creating basic configuration."
      cat > "$ks_yaml" <<EOF
apiVersion: kubescheduler.config.k8s.io/v1
kind: KubeSchedulerConfiguration
clientConnection:
  kubeconfig: "${ks_conf}"
leaderElection:
  leaderElect: true
EOF
    fi

    # CLUSTER_IP is globally defined.
    $SED -i "s~CLUSTER_ADDR~https://${CLUSTER_IP}:6443~g" "$ks_env";
    $SED -i "s~CONFIG_YAML~${ks_yaml}~g" "$ks_env";

    # Update the yaml configuration
    yq_write ".clientConnection.kubeconfig=\"${ks_conf}\"" "$ks_yaml";

    info "finished setup_kube_scheduler"
}

# Improved remote execution by passing environment variables instead of modifying files with sed
function exec_remote() {
    local _script=$1;
    info "started exec_remote ${_script}";
    if [ -f "$config_yaml" ]; then
        for host in $(yq_read ".hosts | .[]?" "$config_yaml"); do
            if [ -n "$host" ]; then
              # Copy necessary files
              exec_c "${SCP_COMMAND} ${_script} ${host}:/tmp/${_script}"
              exec_c "${SCP_COMMAND} ./common.sh ${host}:/tmp/common.sh"
              exec_c "${SCP_COMMAND} ${config_yaml} ${host}:/tmp/config.yaml"
              [ -f "$hosts_yaml" ] && exec_c "${SCP_COMMAND} ${hosts_yaml} ${host}:/tmp/hosts.yaml"
              exec_c "chmod 744 /tmp/${_script}" "${host}"

              # Execute remotely, passing CLEAN variable via environment
              # This avoids the need to use sed on the remote common.sh
              local remote_cmd="CLEAN=${CLEAN} /tmp/${_script} 2> /tmp/${_script}.err 1> /tmp/${_script}.out"
              $SSH_COMMAND "$host" "$remote_cmd" &
              pids[${pids_counter}]=$!;
              pids_counter=$((pids_counter + 1));
              info "started ${_script} on ${host}";
            fi
        done
    fi
    info "finished exec_remote ${_script}";
}

function remote_cleanup() {
    local _script=$1;
    info "started remote_cleanup ${_script}";
    mkdir -p ./logs
    if [ -f "$config_yaml" ]; then
      for host in $(yq_read ".hosts | .[]?" "$config_yaml"); do
          if [ -n "$host" ]; then
            info "remove tmp files from ${host}";
            # Retrieve logs if they exist (use SSH command to check existence first)
            if $SSH_COMMAND "$host" "[ -f /tmp/$_script.err ]"; then
              exec_c "$SCP_COMMAND $host:/tmp/$_script.err ./logs/${host}.$_script.err"
            fi
            if $SSH_COMMAND "$host" "[ -f /tmp/$_script.out ]"; then
              exec_c "$SCP_COMMAND $host:/tmp/$_script.out ./logs/${host}.$_script.out"
            fi
            # Clean up remote files
            exec_c "rm -f /tmp/common.sh /tmp/config.yaml /tmp/hosts.yaml /tmp/${_script} /tmp/${_script}.out" "$host"
          fi
      done
    fi
}

function exec_script() {
    local _script=$1;
    local _remote=${2:-false};
    info "started exec_script ${_script} ${_remote}";
    [ ! -d "./logs" ] && mkdir -p logs;

    if [ ! -f "${script_dir}/$_script" ]; then
      error_message "Script ${_script} does not exist in ${script_dir}" 1;
    fi

    # Execute locally in the script directory
    pushd "$script_dir" >/dev/null

    pids_counter=0;
    info "starting local ${_script}";
    # Pass CLEAN environment variable for local execution as well
    CLEAN=${CLEAN} ./"${_script}" 2> "logs/${_script}.err" 1> "logs/${_script}.out" &
    pids[${pids_counter}]=$!
    pids_counter=$((pids_counter + 1));

    [[ "$_remote" = "true" ]] && exec_remote "$_script";

    # Wait for all background processes
    local exit_status=0
    for pid in "${pids[@]}"; do
        wait "$pid" || {
            # If wait fails, it means the script failed.
            warning "Script ${_script} (PID $pid) finished with non-zero exit status."
            exit_status=1
        }
    done

    info "${_script} finished";
    [[ "$_remote" = "true"  ]] && remote_cleanup "$_script";
    popd >/dev/null
    info "finished exec_script ${_script} ${_remote}";

    # Exit the main script if the executed script failed
    if [ $exit_status -ne 0 ]; then
        error_message "Execution failed in script ${_script}." $exit_status
    fi
}

function ha_proxy_configure() {

    ip_addr=${1};
    _c=${2:-1};
    hap_conf="/etc/haproxy/haproxy.cfg";
    server_str="server k8s-api-${_c} ${ip_addr}:6443 check"
    exec_c "echo \"${server_str}\" >> ${hap_conf}";
}

function vrrp_configure() {

     set_peer_ips;
     host=${1:-"local"};
     prio=${2:-"30"};
     k_conf=${3};
     auth_pass=${4};
     router_id=${5};
     info "started vrrp_configure $host $prio";

     local_hostname=$(hostname);
     intf="";
     if [[ $host == "local" ]]; then
         hostname=$local_hostname;
         host_ip="${peer_ips[${hostname}]}";
         intf=$(ip -br -4 a sh | grep ${host_ip} | awk '{print $1}');
     else
         hostname=$host;
         host_ip="${peer_ips[${hostname}]}";
         intf=$($SSH_COMMAND $host "ip -br -4 a sh | grep ${host_ip} | awk '{print \$1}'");
     fi
     intf="${intf%%@*}";
     ha_proxy_configure $host_ip $prio;
     info "vrrp_configure ${intf}";

     exec_c "sed -i \"s/INTERFACE/${intf}/g\" $k_conf";
     exec_c "sed -i \"s/ROUTER_ID/${router_id}/g\" $k_conf";
     exec_c "sed -i \"s/AUTH_PASS/${auth_pass}/g\" $k_conf";
     exec_c "sed -i \"s~IP_ADDR~$CLUSTER_IP/24~g\" $k_conf";


    info "finished vrrp_configure";
}

function keepalived_configure() {
    info "started keepalived_configure";
    
    # Populate peer_ips if needed
    if [ ${#peer_ips[@]} -eq 0 ]; then
        set_peer_ips;
    fi

    
    # Generate shared authentication password
    local auth_pass=$(openssl rand -hex 4);  # 8 chars for keepalived
    
    # VRRP virtual_router_id - must be the same for all nodes (1-255)
    local vrrp_id="51";  # Same for all nodes in this VRRP group
    
    # Configure HAProxy first
    local hap_conf="/etc/haproxy/haproxy.cfg";
    if [ -f "${CONF_DIR}/haproxy.cfg" ]; then
        exec_c "cp ${CONF_DIR}/haproxy.cfg ${hap_conf}";
        exec_c "sed -i \"s~IP_ADDR~${CLUSTER_IP}~g\" ${hap_conf}";
    else
        error_message "HAProxy template not found: ${CONF_DIR}/haproxy.cfg" 1
        return 1
    fi
    
    # Clear existing backend servers and add all control plane nodes
    sed -i '/^\s*server k8s-api-/d' "$hap_conf"
    
    local counter=1
    for host in "${!peer_ips[@]}"; do
        local ip="${peer_ips[$host]}"
        echo "  server k8s-api-${counter} ${ip}:6443 check" >> "$hap_conf"
        counter=$((counter + 1))
    done
    
    # Sort hosts to determine priority order consistently
    local sorted_hosts=($(for h in "${!peer_ips[@]}"; do echo "$h"; done | sort))
    
    # Configure keepalived on local node
    local hostname=$(hostname);
    local short_hostname=$(hostname -s);  # Short hostname for router_id
    local host_ip="${peer_ips[$hostname]}"
    
    if [ -z "$host_ip" ]; then
        error_message "Cannot find IP for hostname ${hostname} in peer_ips" 1
        return 1
    fi
    
    local intf=$(ip -br -4 a sh | grep "${host_ip}" | awk '{print $1}');
    intf="${intf%%@*}";
    
    if [ -z "$intf" ]; then
        error_message "Cannot determine network interface for IP ${host_ip}" 1
        return 1
    fi
    
    # Determine VLAN interface for VIP
    local vip_intf="$intf"
    # Check if VIP should be on a VLAN
    if ip -br a sh | grep -q "vlan12"; then
        vip_intf="vlan12"
    fi
    
    info "Configuring keepalived on interface ${intf} with VIP ${CLUSTER_IP} on ${vip_intf}";
    info "Local node router_id: ${short_hostname}, VRRP ID: ${vrrp_id}";
    
    # Create keepalived config from template
    local k_conf="/etc/keepalived/keepalived.conf";
    local k_conf_template="${CONF_DIR}/keepalived.conf";
    
    if [ ! -f "$k_conf_template" ]; then
        error_message "Keepalived template not found: ${k_conf_template}" 1
        return 1
    fi
    
    mkdir -p "$(dirname $k_conf)"
    
    # Determine state and priority for local node
    # HIGHER priority becomes MASTER
    local state="BACKUP"
    local priority=90
    
    for i in "${!sorted_hosts[@]}"; do
        if [ "${sorted_hosts[$i]}" = "$hostname" ]; then
            if [ $i -eq 0 ]; then
                state="MASTER"
                priority=100  # Highest priority for MASTER
            else
                priority=$((100 - i*5))  # 100, 95, 90, 85, etc.
            fi
            break
        fi
    done
    
    info "Local node $hostname will be $state with priority $priority"
    
    # Build unicast peers list (all nodes except self)
    local peers=""
    for host in "${!peer_ips[@]}"; do
        if [ "$host" != "$hostname" ]; then
            peers="${peers}        ${peer_ips[$host]}\n"
        fi
    done
    
    # Create config from template
    cp "$k_conf_template" "$k_conf"
    
    # Substitute all placeholders
    sed -i "s/HOSTNAME/${short_hostname}/g" "$k_conf"  # router_id in global_defs
    sed -i "s/INTERFACE/${intf}/g" "$k_conf"
    sed -i "s/VRRP_ID/${vrrp_id}/g" "$k_conf"  # virtual_router_id in vrrp_instance
    sed -i "s/STATE/${state}/g" "$k_conf"
    sed -i "s/PRIO/${priority}/g" "$k_conf"
    sed -i "s/AUTH_PASS/${auth_pass}/g" "$k_conf"
    sed -i "s~IP_ADDR/24~${CLUSTER_IP}/24~g" "$k_conf"
    sed -i "s~IP_ADDR_HOST~${host_ip}~g" "$k_conf"
    sed -i "s~IP_ADDR~${CLUSTER_IP}~g" "$k_conf"
    sed -i "s/VIP_INTERFACE/${vip_intf}/g" "$k_conf"
    
    # Replace PEERS placeholder with actual peer list
    if [ -n "$peers" ]; then
        echo -e "$peers" > /tmp/peers_list
        sed -i "/PEERS/r /tmp/peers_list" "$k_conf"
        sed -i "/PEERS/d" "$k_conf"
        rm -f /tmp/peers_list
    else
        # If no peers (single node), remove unicast_peer block
        sed -i '/unicast_peer {/,/}/d' "$k_conf"
    fi
    
    # Configure remote nodes
    if [ -f "$config_yaml" ]; then
        for host in $(yq_read ".hosts | .[]?" $config_yaml); do
            if [ -n "$host" ]; then
                info "Configuring keepalived on ${host}";
                
                # Copy HAProxy config
                exec_c "$SCP_COMMAND ${hap_conf} $host:${hap_conf}"
                
                # Get remote hostname for router_id
                local remote_hostname=$($SSH_COMMAND "$host" hostname);
                local remote_short_hostname=$($SSH_COMMAND "$host" hostname -s);
                local remote_ip="${peer_ips[$remote_hostname]}"
                
                if [ -z "$remote_ip" ]; then
                    warning "Cannot find IP for remote host ${remote_hostname}"
                    continue
                fi
                
                # Get remote interface
                local remote_intf=$($SSH_COMMAND "$host" "ip -br -4 a sh | grep ${remote_ip} | awk '{print \$1}'");
                remote_intf="${remote_intf%%@*}";
                
                # Check for VLAN interface on remote
                local remote_vip_intf="$remote_intf"
                if $SSH_COMMAND "$host" "ip -br a sh | grep -q vlan12"; then
                    remote_vip_intf="vlan12"
                fi
                
                # Determine remote state and priority
                local remote_state="BACKUP"
                local remote_priority=90
                
                for i in "${!sorted_hosts[@]}"; do
                    if [ "${sorted_hosts[$i]}" = "$remote_hostname" ]; then
                        if [ $i -eq 0 ]; then
                            remote_state="MASTER"
                            remote_priority=100
                        else
                            remote_priority=$((100 - i*5))
                        fi
                        break
                    fi
                done
                
                info "Remote node ${remote_hostname} (router_id: ${remote_short_hostname}) will be ${remote_state} with priority ${remote_priority}"
                
                # Build remote peers list
                local remote_peers=""
                for peer_host in "${!peer_ips[@]}"; do
                    if [ "$peer_host" != "$remote_hostname" ]; then
                        remote_peers="${remote_peers}        ${peer_ips[$peer_host]}\n"
                    fi
                done
                
                # Create remote config
                local k_conf_tmp="/tmp/keepalived-${remote_hostname}.conf"
                cp "$k_conf_template" "$k_conf_tmp"
                
                sed -i "s/HOSTNAME/${remote_short_hostname}/g" "$k_conf_tmp"  # Unique router_id
                sed -i "s/INTERFACE/${remote_intf}/g" "$k_conf_tmp"
                sed -i "s/VRRP_ID/${vrrp_id}/g" "$k_conf_tmp"  # Same VRRP ID for all
                sed -i "s/STATE/${remote_state}/g" "$k_conf_tmp"
                sed -i "s/PRIO/${remote_priority}/g" "$k_conf_tmp"
                sed -i "s/AUTH_PASS/${auth_pass}/g" "$k_conf_tmp"
                sed -i "s~IP_ADDR_HOST~${remote_ip}~g" "$k_conf_tmp"
                sed -i "s~IP_ADDR/24~${CLUSTER_IP}/24~g" "$k_conf_tmp"
                sed -i "s~IP_ADDR~${CLUSTER_IP}~g" "$k_conf_tmp"
                sed -i "s/VIP_INTERFACE/${remote_vip_intf}/g" "$k_conf_tmp"
                
                if [ -n "$remote_peers" ]; then
                    echo -e "$remote_peers" > /tmp/remote_peers_list
                    sed -i "/PEERS/r /tmp/remote_peers_list" "$k_conf_tmp"
                    sed -i "/PEERS/d" "$k_conf_tmp"
                    rm -f /tmp/remote_peers_list
                else
                    sed -i '/unicast_peer {/,/}/d' "$k_conf_tmp"
                fi
                
                # Copy to remote
                exec_c "$SCP_COMMAND ${k_conf_tmp} $host:${k_conf}"
                rm -f "$k_conf_tmp"
                
            fi
        done
    fi
    
    info "finished keepalived_configure";
}

function kube_configure() {
    info "started kube_configure";

    install_certs;
    create_kubeconfigs;
    create_kubelet_kubeconfig;
    kube_service_install;

    # Set ownership locally (install_certs handles KUBE_PKI for KUBE_USER)
    # Handle ETCD ownership specifically
    if [ -d "$ETCD_PKI" ]; then
        # Change ownership of ETCD PKI directory and contents to etcd user/group
        exec_c "chown -R ${ETCD_USER}:${ETCD_GROUP} ${ETCD_PKI}"
        # Ensure keys within ETCD PKI are group-readable by kube group if necessary (e.g., if apiserver needs to read ETCD CA)
        # Adjusting permissions slightly for flexibility
        find "$ETCD_PKI" -type f -name "*.key" -exec chmod 0640 {} \;
        chgrp -R ${KUBE_GROUP} ${ETCD_PKI}
    fi


    # Trust CAs locally (if 'trust' command is available)
    if command -v trust >/dev/null 2>&1; then
        for ca_cert in "${KUBE_PKI}/ca.crt" "${KUBE_PKI}/front-proxy-ca.crt" "${ETCD_PKI}/ca.crt"; do
            [ -f "$ca_cert" ] && exec_c "trust anchor ${ca_cert}"
        done
    fi

    # Configure remote hosts
    if [ -f "$config_yaml" ]; then
        for host in $(yq_read ".hosts | .[]?" "$config_yaml"); do
            if [ -n "$host" ]; then
              info "copy configuration to ${host}";
              # Configuration synchronization is handled by kube_service_install and create_kubeconfigs/kubelet_kubeconfig.
              # We mainly need to ensure PKI data is synchronized and permissions are correct.

              # Ensure remote directories exist
              exec_c "mkdir -p ${KUBE_PKI} ${ETCD_PKI}" "$host"

              # Use rsync over SSH for efficient PKI transfer
              if command -v rsync >/dev/null 2>&1; then
                  local rsync_cmd="rsync -avz -e \"${SSH_COMMAND}\""
                  exec_c "${rsync_cmd} ${KUBE_PKI}/ ${host}:${KUBE_PKI}/"
              else
                  # Fallback to SCP if rsync is not available
                  exec_c "$SCP_COMMAND -r $KUBE_PKI/* $host:$KUBE_PKI/"
              fi

              # Set ownership remotely
              exec_c "chown -R ${KUBE_USER}:${KUBE_GROUP} ${KUBE_DIR} ${KUBE_PKI}" "$host"
              # Apply specific ETCD ownership/permissions remotely
              exec_c "chown -R ${ETCD_USER}:${ETCD_GROUP} ${ETCD_PKI}" "$host"
              exec_c "find ${ETCD_PKI} -type f -name \"*.key\" -exec chmod 0640 {} \;" "$host"
              exec_c "chgrp -R ${KUBE_GROUP} ${ETCD_PKI}" "$host"


              # Trust CAs remotely
              if $SSH_COMMAND "$host" "command -v trust >/dev/null 2>&1"; then
                  for ca_cert in "${KUBE_PKI}/ca.crt" "${KUBE_PKI}/front-proxy-ca.crt" "${ETCD_PKI}/ca.crt"; do
                      exec_c "trust anchor ${ca_cert}" "$host"
                  done
              fi
            fi
        done
    fi

    info "finished kube_configure";
}


function check_etcd_data_exists() {
    local host=${1:-"local"}
    
    if [ "$host" = "local" ]; then
        [ -d "${ETCD_DATA_DIR}/member" ] && return 0 || return 1
    else
        $SSH_COMMAND "$host" "[ -d ${ETCD_DATA_DIR}/member ]" && return 0 || return 1
    fi
}

function get_etcd_cluster_state() {
    info "Checking ETCD cluster state"
    
    local existing_nodes=0
    local total_nodes=1  # Count local node
    
    # Check local node
    if check_etcd_data_exists "local"; then
        existing_nodes=$((existing_nodes + 1))
        info "Found existing ETCD data on local node"
    fi
    
    # Check remote nodes
    if [ -f "$config_yaml" ]; then
        for host in $(yq_read ".hosts | .[]?" "$config_yaml"); do
            if [ -n "$host" ]; then
                total_nodes=$((total_nodes + 1))
                if check_etcd_data_exists "$host"; then
                    existing_nodes=$((existing_nodes + 1))
                    info "Found existing ETCD data on $host"
                fi
            fi
        done
    fi
    
    info "ETCD cluster state: $existing_nodes/$total_nodes nodes have existing data"
    
    # Return cluster state
    if [ $existing_nodes -eq 0 ]; then
        echo "new"
    elif [ $existing_nodes -eq $total_nodes ]; then
        echo "existing"
    else
        echo "partial"
    fi
}

function update_etcd_cluster_state() {
    local host=${1:-"local"}
    local cluster_state=$2  # "new" or "existing"
    
    info "Setting ETCD cluster state to '$cluster_state' on $host"
    
    local etcd_yml="${ETCD_CONF}/etcd.conf.yml"
    
    if [ "$host" = "local" ]; then
        yq_write ".\"initial-cluster-state\"=\"${cluster_state}\"" "$etcd_yml"
    else
        # Update remote config
        local tmp_config="/tmp/etcd.conf.yml.${host}"
        $SCP_COMMAND "$host:$etcd_yml" "$tmp_config"
        yq_write ".\"initial-cluster-state\"=\"${cluster_state}\"" "$tmp_config"
        $SCP_COMMAND "$tmp_config" "$host:$etcd_yml"
        rm -f "$tmp_config"
    fi
}

function wait_for_etcd_healthy() {
    local endpoint=$1
    local max_attempts=30
    local attempt=1
    
    info "Waiting for ETCD endpoint $endpoint to become healthy"
    
    while [ $attempt -le $max_attempts ]; do
        if $etcdctl --endpoints="$endpoint" \
                   --cacert="${ETCD_PKI}/ca.crt" \
                   --cert="${ETCD_PKI}/healthcheck-client.crt" \
                   --key="${ETCD_PKI}/healthcheck-client.key" \
                   endpoint health &>/dev/null; then
            info "ETCD endpoint $endpoint is healthy"
            return 0
        fi
        
        sleep 2
        attempt=$((attempt + 1))
    done
    
    warning "ETCD endpoint $endpoint did not become healthy after $max_attempts attempts"
    return 1
}

function start_etcd_cluster() {
    info "Starting ETCD cluster"
    
    local etcdctl=$(command -v etcdctl || true)
    if [ -z "$etcdctl" ]; then
        warning "etcdctl not found, falling back to simple systemctl start"
        start_etcd_simple
        return
    fi
    
    # Ensure ETCDCTL uses v3 API
    export ETCDCTL_API=3
    
    # Get cluster state
    local cluster_state=$(get_etcd_cluster_state)
    
    info "Cluster state determined as: $cluster_state"
    
    case "$cluster_state" in
        "new")
            start_etcd_new_cluster
            ;;
        "existing")
            start_etcd_existing_cluster
            ;;
        "partial")
            handle_etcd_partial_state
            ;;
        *)
            error_message "Unknown cluster state: $cluster_state" 1
            ;;
    esac
}

function start_etcd_new_cluster() {
    info "Starting new ETCD cluster"
    
    # Ensure all nodes are configured for "new" cluster
    update_etcd_cluster_state "local" "new"
    
    if [ -f "$config_yaml" ]; then
        for host in $(yq_read ".hosts | .[]?" "$config_yaml"); do
            if [ -n "$host" ]; then
                update_etcd_cluster_state "$host" "new"
            fi
        done
    fi
    
    # Start all ETCD nodes simultaneously for new cluster
    info "Starting ETCD on local node"
    exec_c "${SYSTEMCTL} start etcd"
    
    if [ -f "$config_yaml" ]; then
        for host in $(yq_read ".hosts | .[]?" "$config_yaml"); do
            if [ -n "$host" ]; then
                info "Starting ETCD on $host"
                exec_c "${SYSTEMCTL} start etcd" "$host"
            fi
        done
    fi
    
    # Wait for cluster to form
    sleep 5
    
    # Verify cluster health
    verify_etcd_cluster_health
}

function start_etcd_existing_cluster() {
    info "Starting existing ETCD cluster"
    
    # For existing cluster, set state to "existing"
    update_etcd_cluster_state "local" "existing"
    
    if [ -f "$config_yaml" ]; then
        for host in $(yq_read ".hosts | .[]?" "$config_yaml"); do
            if [ -n "$host" ]; then
                update_etcd_cluster_state "$host" "existing"
            fi
        done
    fi
    
    # Start nodes one by one to avoid split-brain
    local hostname=$(hostname)
    local local_endpoint="https://${peer_ips[$hostname]}:2379"
    
    info "Starting ETCD on local node"
    exec_c "${SYSTEMCTL} start etcd"
    
    # Wait for local node to be healthy
    wait_for_etcd_healthy "$local_endpoint"
    
    # Start remote nodes one by one
    if [ -f "$config_yaml" ]; then
        for host in $(yq_read ".hosts | .[]?" "$config_yaml"); do
            if [ -n "$host" ]; then
                info "Starting ETCD on $host"
                exec_c "${SYSTEMCTL} start etcd" "$host"
                
                # Wait for remote node to join
                local remote_hostname=$($SSH_COMMAND "$host" hostname)
                local remote_endpoint="https://${peer_ips[$remote_hostname]}:2379"
                wait_for_etcd_healthy "$remote_endpoint"
            fi
        done
    fi
    
    # Verify cluster health
    verify_etcd_cluster_health
}

function handle_etcd_partial_state() {
    warning "ETCD cluster in partial state - some nodes have data, others don't"
    info "This typically happens when nodes were added/removed incorrectly"
    
    # Check if we can form a quorum with existing nodes
    local existing_nodes=0
    local total_nodes=1
    local nodes_with_data=""
    
    if check_etcd_data_exists "local"; then
        existing_nodes=$((existing_nodes + 1))
        nodes_with_data="local"
    fi
    
    if [ -f "$config_yaml" ]; then
        for host in $(yq_read ".hosts | .[]?" "$config_yaml"); do
            if [ -n "$host" ]; then
                total_nodes=$((total_nodes + 1))
                if check_etcd_data_exists "$host"; then
                    existing_nodes=$((existing_nodes + 1))
                    nodes_with_data="$nodes_with_data $host"
                fi
            fi
        done
    fi
    
    local quorum=$((total_nodes / 2 + 1))
    
    if [ $existing_nodes -ge $quorum ]; then
        info "Have quorum with $existing_nodes nodes, attempting to recover cluster"
        
        # Start nodes with existing data first
        if echo "$nodes_with_data" | grep -q "local"; then
            update_etcd_cluster_state "local" "existing"
            exec_c "${SYSTEMCTL} start etcd"
        fi
        
        for host in $nodes_with_data; do
            if [ "$host" != "local" ]; then
                update_etcd_cluster_state "$host" "existing"
                exec_c "${SYSTEMCTL} start etcd" "$host"
            fi
        done
        
        # Wait for cluster to stabilize
        sleep 5
        
        # Now add nodes without data as new members
        add_missing_etcd_members
        
    else
        error_message "Cannot form quorum with only $existing_nodes/$total_nodes nodes having data. Manual intervention required." 1
        info "Options:"
        info "1. If data is not important: Clean all nodes with 'rm -rf ${ETCD_DATA_DIR}' and start fresh"
        info "2. If data is important: Restore from backup or recover manually"
        return 1
    fi
}

function add_missing_etcd_members() {
    info "Adding nodes without data as new cluster members"
    
    # Build endpoints list from running nodes
    local endpoints=""
    if [ ${#peer_ips[@]} -eq 0 ]; then
        set_peer_ips;
    fi
    
    for host in "${!peer_ips[@]}"; do
        if check_etcd_data_exists "$host" || [ "$host" = "$(hostname)" -a -d "${ETCD_DATA_DIR}/member" ]; then
            if [ -n "$endpoints" ]; then
                endpoints="${endpoints},"
            fi
            endpoints="${endpoints}https://${peer_ips[$host]}:2379"
        fi
    done
    
    export ETCDCTL_ENDPOINTS="$endpoints"
    export ETCDCTL_CACERT="${ETCD_PKI}/ca.crt"
    export ETCDCTL_CERT="${ETCD_PKI}/healthcheck-client.crt"
    export ETCDCTL_KEY="${ETCD_PKI}/healthcheck-client.key"
    
    # Add nodes without data
    local hostname=$(hostname)
    
    if ! check_etcd_data_exists "local"; then
        info "Adding local node as new member"
        $etcdctl member add "$hostname" --peer-urls="https://${peer_ips[$hostname]}:2380"
        
        # Update config for existing cluster member
        update_etcd_cluster_state "local" "existing"
        exec_c "${SYSTEMCTL} start etcd"
    fi
    
    if [ -f "$config_yaml" ]; then
        for host in $(yq_read ".hosts | .[]?" "$config_yaml"); do
            if [ -n "$host" ] && ! check_etcd_data_exists "$host"; then
                local remote_hostname=$($SSH_COMMAND "$host" hostname)
                info "Adding $remote_hostname as new member"
                
                $etcdctl member add "$remote_hostname" --peer-urls="https://${peer_ips[$remote_hostname]}:2380"
                
                update_etcd_cluster_state "$host" "existing"
                exec_c "${SYSTEMCTL} start etcd" "$host"
            fi
        done
    fi
}

function verify_etcd_cluster_health() {
    info "Verifying ETCD cluster health"
    
    local etcdctl=$(command -v etcdctl || true)
    if [ -z "$etcdctl" ]; then
        warning "etcdctl not found, cannot verify cluster health"
        return
    fi
    
    # Build endpoints list
    local endpoints=""
    if [ ${#peer_ips[@]} -eq 0 ]; then
        set_peer_ips;
    fi
    
    for host in "${!peer_ips[@]}"; do
        if [ -n "$endpoints" ]; then
            endpoints="${endpoints},"
        fi
        endpoints="${endpoints}https://${peer_ips[$host]}:2379"
    done
    
    export ETCDCTL_API=3
    export ETCDCTL_ENDPOINTS="$endpoints"
    export ETCDCTL_CACERT="${ETCD_PKI}/ca.crt"
    export ETCDCTL_CERT="${ETCD_PKI}/healthcheck-client.crt"
    export ETCDCTL_KEY="${ETCD_PKI}/healthcheck-client.key"
    
    # Check endpoint health
    info "Endpoint health check:"
    $etcdctl endpoint health
    
    # Check member list
    info "Cluster members:"
    $etcdctl member list
    
    # Check endpoint status
    info "Endpoint status:"
    $etcdctl endpoint status --write-out=table
}

function start_etcd_simple() {
    info "Starting ETCD with simple systemctl (no cluster coordination)"
    
    exec_c "${SYSTEMCTL} start etcd"
    
    if [ -f "$config_yaml" ]; then
        for host in $(yq_read ".hosts | .[]?" "$config_yaml"); do
            if [ -n "$host" ]; then
                exec_c "${SYSTEMCTL} start etcd" "$host"
            fi
        done
    fi
}

function stop_etcd_cluster() {
    info "starting graceful ETCD cluster shutdown";
    
    local etcdctl=$(command -v etcdctl || true)
    if [ -z "$etcdctl" ]; then
        warning "etcdctl not found, falling back to systemctl stop"
        exec_c "${SYSTEMCTL} stop etcd"
        if [ -f "$config_yaml" ]; then
            for host in $(yq_read ".hosts | .[]?" "$config_yaml"); do
                [ -n "$host" ] && exec_c "${SYSTEMCTL} stop etcd" "$host"
            done
        fi
        return
    fi
    
    # Build ETCD endpoints list
    local endpoints=""
    if [ ${#peer_ips[@]} -eq 0 ]; then
        set_peer_ips;
    fi
    
    for host in "${!peer_ips[@]}"; do
        if [ -n "$endpoints" ]; then
            endpoints="${endpoints},"
        fi
        endpoints="${endpoints}https://${peer_ips[$host]}:2379"
    done
    
    # Set ETCD client environment
    export ETCDCTL_API=3
    export ETCDCTL_ENDPOINTS="$endpoints"
    export ETCDCTL_CACERT="${ETCD_PKI}/ca.crt"
    export ETCDCTL_CERT="${ETCD_PKI}/healthcheck-client.crt"
    export ETCDCTL_KEY="${ETCD_PKI}/healthcheck-client.key"
    
    # Check cluster health before shutdown
    info "Checking ETCD cluster health before shutdown"
    $etcdctl endpoint health || warning "Some ETCD endpoints unhealthy"
    
    # Get member list
    local members=$($etcdctl member list --write-out=json | jq -r '.members[].name')
    
    # Transfer leadership if possible (for the current leader)
    local hostname=$(hostname)
    local leader_id=$($etcdctl endpoint status --write-out=json | jq -r '.[] | select(.Status.leader == .Status.header.member_id) | .Status.header.member_id')
    
    if [ -n "$leader_id" ]; then
        info "Current leader ID: $leader_id"
        # Try to move leader before shutdown
        local non_leader=$($etcdctl endpoint status --write-out=json | jq -r '.[] | select(.Status.leader != .Status.header.member_id) | .Status.header.member_id' | head -1)
        if [ -n "$non_leader" ]; then
            info "Attempting to transfer leadership to member $non_leader"
            $etcdctl move-leader "$non_leader" || warning "Leadership transfer failed"
            sleep 2
        fi
    fi
    
    # Stop ETCD on all nodes gracefully
    info "Stopping ETCD services on all nodes"
    
    # Stop local ETCD
    exec_c "${SYSTEMCTL} stop etcd"
    
    # Stop remote ETCD nodes
    if [ -f "$config_yaml" ]; then
        for host in $(yq_read ".hosts | .[]?" "$config_yaml"); do
            if [ -n "$host" ]; then
                info "Stopping ETCD on $host"
                exec_c "${SYSTEMCTL} stop etcd" "$host"
            fi
        done
    fi
    
    info "finished graceful ETCD cluster shutdown";
}

# Updated manage_services to use the new ETCD start function
function manage_services() {
    local _s=${1:-stop};
    info "started manage_services ${_s}";

    if [ -z "$SYSTEMCTL" ]; then
        warning "systemctl not found, cannot manage services."
        return
    fi

    local sys_reload="${SYSTEMCTL} daemon-reload";
    exec_c "${sys_reload}"

    if [ -f "$config_yaml" ]; then
        for host in $(yq_read ".hosts | .[]?" "$config_yaml"); do
            [ -n "$host" ] && exec_c "${sys_reload}" "$host"
        done
    fi

    if [ "$_s" = "start" ]; then
        # Start containerd first
        exec_c "${SYSTEMCTL} start containerd" || warning "Failed to start containerd"
        if [ -f "$config_yaml" ]; then
            for host in $(yq_read ".hosts | .[]?" "$config_yaml"); do
                [ -n "$host" ] && exec_c "${SYSTEMCTL} start containerd" "$host" || warning "Failed to start containerd on $host"
            done
        fi
        
        # Start ETCD cluster with proper coordination
        start_etcd_cluster
        
        # Start remaining services
        local services=("haproxy" "keepalived" "kubelet" "kube-proxy" "kube-apiserver" "kube-scheduler" "kube-controller-manager")
        for service in "${services[@]}"; do
            if $SYSTEMCTL list-unit-files | grep -q "^${service}.service"; then
                exec_c "${SYSTEMCTL} start ${service}" || warning "Failed to start ${service}"
            fi
            
            if [ -f "$config_yaml" ]; then
                for host in $(yq_read ".hosts | .[]?" "$config_yaml"); do
                    if [ -n "$host" ]; then
                        if $SSH_COMMAND "$host" "$SYSTEMCTL list-unit-files | grep -q '^${service}.service'"; then
                            exec_c "${SYSTEMCTL} start ${service}" "$host" || warning "Failed to start ${service} on $host"
                        fi
                    fi
                done
            fi
        done
    else
        # Stop order
        local services=("kube-controller-manager" "kube-scheduler" "kube-apiserver" "kube-proxy" "kubelet" "keepalived" "haproxy")
        for service in "${services[@]}"; do
            if $SYSTEMCTL list-unit-files | grep -q "^${service}.service"; then
                exec_c "${SYSTEMCTL} stop ${service}" || warning "Failed to stop ${service}"
            fi
            
            if [ -f "$config_yaml" ]; then
                for host in $(yq_read ".hosts | .[]?" "$config_yaml"); do
                    if [ -n "$host" ]; then
                        if $SSH_COMMAND "$host" "$SYSTEMCTL list-unit-files | grep -q '^${service}.service'"; then
                            exec_c "${SYSTEMCTL} stop ${service}" "$host" || warning "Failed to stop ${service} on $host"
                        fi
                    fi
                done
            fi
        done
        
        # Stop ETCD cluster gracefully
        stop_etcd_cluster
        
        # Stop containerd last
        exec_c "${SYSTEMCTL} stop containerd" || true
        if [ -f "$config_yaml" ]; then
            for host in $(yq_read ".hosts | .[]?" "$config_yaml"); do
                [ -n "$host" ] && exec_c "${SYSTEMCTL} stop containerd" "$host" || true
            done
        fi
    fi
    
    info "finished manage_services ${_s}";
}

function stop_services() {
    info "stop_services";
    manage_services "stop";
}

function start_services() {
    info "start_services";
    manage_services "start";
}

function cleanup() {
    info "started cleanup";
    [ "$SERVICES" = "true" ] && stop_services;

    local kubelet_dir
    kubelet_dir=$(yq_read '.kubeletDir' "$config_yaml");
    local kube_proxy_dir
    kube_proxy_dir=$(yq_read '.kubeProxyDir' "$config_yaml");

    # Local cleanup
    [ -d "./logs" ] && rm -rf logs/*.{err,out}
    exec_c "rm -rf $KUBE_DIR $ETCD_DATA_DIR $kubelet_dir $kube_proxy_dir $KUBE_PKI"
    exec_c "rm -f /tmp/cluster.token"

    # Remote cleanup
    if [ -f "$config_yaml" ]; then
      for host in $(yq_read ".hosts | .[]?" "$config_yaml"); do
          if [ -n "$host" ]; then
            exec_c "rm -rf $KUBE_DIR $ETCD_DATA_DIR $kubelet_dir $kube_proxy_dir $KUBE_PKI /tmp/cluster.token" "$host"
          fi
      done
    fi
}

function trap_sigint() {
    info "started trap_sigint";
    # Attempt graceful termination first
    for pid in "${pids[@]}"; do
        kill -INT "$pid" 2>/dev/null || true;
    done
    sleep 2
    # Force kill if still running
    for pid in "${pids[@]}"; do
        if kill -0 "$pid" 2>/dev/null; then
            kill -9 "$pid" 2>/dev/null || true;
        fi
    done
    error_message "SIGINT received, processes terminated." 130
}

# Removed unused function argparse

function main() {
    info "started main";
    # Setup trap
    trap trap_sigint INT

    if [ "$CLEAN" = "true" ]; then
      info "Running cleanup..."
      cleanup;
    fi

    # Always stop services before starting setup if SERVICES=true
    if [ "$SERVICES" = "true" ]; then
      info "Stopping services..."
      stop_services;
    fi

    set_peer_ips;

    if [ "$BUILD_SOURCE" = "true" ]; then
      info "Running source-builder.sh..."
      exec_script "source-builder.sh" true
    fi

    generate_etcd_token;

    if [ "$RUN_CERTS" = "true" ]; then
      info "Running cert-manager.sh..."
      exec_script "cert-manager.sh" false
    fi

    keepalived_configure;
    kube_configure;

    if [ "$RUN_SETUP" = "true" ]; then
        info "Running setup-sources.sh..."
        exec_script "setup-sources.sh" true
    fi

    if [ "$SERVICES" = "true" ]; then
      info "Starting services..."
      start_services;
    fi

    provision_calico;
    info "finished main";
}

# Argument parsing
# Note: Options logic is inverted (e.g., -s sets BUILD_SOURCE=false)
ARGS=$(getopt -o scxylh --long src,certs,setup,services,clean,help -n "$(basename "$0")" -- "$@") || {
    printf "%s" "${usage}";
    exit 1;
}

eval set -- "$ARGS"
while true; do
    case "$1" in
    -s | --src)
        BUILD_SOURCE=false;
        shift;
        ;;
    -c | --certs)
        RUN_CERTS=false;
        shift;
        ;;
    -x | --setup)
        RUN_SETUP=false;
        shift;
        ;;
    -y | --services)
        SERVICES=false;
        shift;
        ;;
    -l | --clean)
        CLEAN=true;
        shift;
        ;;
    -h | --help)
        printf "%s" "${usage}";
        exit 0;
        ;;
    --) shift;
        break
        ;;
    *)
        error_message "Internal error in argument parsing." 1
        ;;
  esac
done

main;
